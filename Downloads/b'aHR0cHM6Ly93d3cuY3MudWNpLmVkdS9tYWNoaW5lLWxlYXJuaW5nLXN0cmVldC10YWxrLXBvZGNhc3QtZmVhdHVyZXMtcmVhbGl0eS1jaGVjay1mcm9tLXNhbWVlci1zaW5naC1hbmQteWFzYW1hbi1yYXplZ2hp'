https://www.cs.uci.edu/machine-learning-street-talk-podcast-features-reality-check-from-sameer-singh-and-yasaman-razeghi




Machine Learning ‘Street Talk’ Podcast Features Reality Check from Sameer Singh and Yasaman Razeghi 



 





































 this is a widget called second front page widget area

Explore

Contact Us


Faculty
Research

Research Areas
Research Centers


Graduate Degrees

Computer Science Programs
Current Graduate Students


Undergraduate Degrees
News  & Events

News
Seminar Series
Distinguished Lecture Series
Research Showcase


Apply Now

Undergraduate Admissions
Graduate Admissions
Faculty Candidates


Machine Learning ‘Street Talk’ Podcast Features Reality Check from Sameer Singh and Yasaman Razeghi
April 12, 2022 
A popular machine learning podcast, ML Street Talk, recently featured Computer Science Professor Sameer Singh and Ph.D. student Yasaman Razeghi discussing their paper, “Impact of Pretraining Term Frequencies on Few-Shot Reasoning.” Co-authored with Robert Logan, also a Ph.D. student in UCI’s Donald Bren School of Information and Computer Sciences (ICS), and Matt Gardner, a principal researcher at Microsoft, the paper suggests that large language models perform well on reasoning tasks not because the models can reason well but maybe because they’ve memorized the dataset.


Sameer Singh
Yasaman Razeghi
Robert Logan


“Thank you for writing this paper,” says co-host Keith Duggar during the podcast (available on YouTube and Anchor). “You bring up this absolutely crucial point that the pre-training data has to be considered when you’re talking about the performance of the model [and] this paper directly strikes at and proves it’s not doing reasoning.”
Co-host Tim Scarfe agrees, “I think your work is a bit of a reality check.”
Duggar and Scarfe aren’t the only people in the machine learning world to praise the paper. “Incredibly important result,” tweeted Gary Marcus, founder and CEO of Robust.AI. “Quite interesting analysis that shows large language model few-shot performance for arithmetic is correlated with the training set term frequency of the numbers in the arithmetic expression,” tweeted Jeff Dean, senior fellow and senior VP of Google AI.
“We are among the first to show the effect of large pre-trained corpus on the model’s performance,” says Razeghi. “Our analysis shows that their performance is pretty sensitive to statistics from the pre-training data, and raising serious concerns about the robustness of their reasoning capabilities.”
Razeghi, who will be interning with the Blueshift at Google Research this summer, goes on to say that she hopes “more people take the effect of pre-training corpus into account while they are evaluating the language models.”
— Shani Murray
« ICS Researchers Win Best Paper Award at Eurosys 2022Multidisciplinary Collaborators Set their Sights on Color Vision in the Dark »

Latest news


Senior Spotlight: Tennis Player and CS Major Matthew Sah Serves Up Aces On and Off the Court
September 28, 2022


Register Today for the Southern California AI & Biomedicine Symposium
September 20, 2022


CPO Magazine: “A Legal View of New NIST Quantum-Resistant Algorithms” by Bryan Cunningham
September 19, 2022


UCI Ranked 24th in Undergraduate Computer Science Programs by U.S. News & World Report
September 16, 2022


Senior Spotlight: Jose Cisneros Builds Impressive Resume with Trio of Internships
September 15, 2022




 





© 2022 UC Regents
Feedback
Privacy Policy



 




